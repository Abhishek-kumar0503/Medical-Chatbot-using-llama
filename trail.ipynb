{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello|\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-communityNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (3.10.8)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.3.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 357.1 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.5/2.4 MB 357.1 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.5/2.4 MB 357.1 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 0.8/2.4 MB 409.3 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 535.7 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.6/2.4 MB 729.8 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 896.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 972.2 kB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (0.3.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting pinecone-client\n",
      "  Using cached pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting ctransformers\n",
      "  Downloading ctransformers-0.2.27-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (3.10.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from ctransformers) (0.25.1)\n",
      "Collecting py-cpuinfo<10.0.0,>=9.0.0 (from ctransformers)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub->ctransformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub->ctransformers) (2024.9.0)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
      "Using cached pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 6.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/9.9 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/9.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.7/9.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/9.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pinecone-client, ctransformers\n",
      "Successfully installed ctransformers-0.2.27 pinecone-client-5.0.1 py-cpuinfo-9.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain pinecone-client ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.24.10-cp312-none-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.10 (from pymupdf)\n",
      "  Downloading PyMuPDFb-1.24.10-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.24.10-cp312-none-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.8/3.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.8/3.2 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.6/3.2 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading PyMuPDFb-1.24.10-py3-none-win_amd64.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.2 MB 5.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/13.2 MB 5.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.6/13.2 MB 4.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.1/13.2 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.9/13.2 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.0/13.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.8/13.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.6/13.2 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.8/13.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/13.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.9/13.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.4/13.2 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.7/13.2 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.2/13.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.0/13.2 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.2/13.2 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.7/13.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.7/13.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.3/13.2 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDFb, pymupdf\n",
      "Successfully installed PyMuPDFb-1.24.10 pymupdf-1.24.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.25.1)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.3.8)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (3.1.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.20.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (4.45.1)\n",
      "Requirement already satisfied: filelock in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.130)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: sympy in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.document_loaders import PyMuPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"c6ce942a-5f94-4668-bc1d-2ebae7713e40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from PDF files\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyMuPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 0 of document data\\Gale Encyclopedia of Medicine. Vol. 1. 2nd Edition ( PDFDrive ).pdf\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunks:  5779\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embeddings model\n",
    "def download_huggingface_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_19856\\192741830.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
      "d:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_huggingface_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "), model_name='sentence-transformers/paraphrase-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my query result:  384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello, how are you?\")\n",
    "print(\"length of my query result: \", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5421559810638428,\n",
       " 0.18908195197582245,\n",
       " 0.8348346948623657,\n",
       " 0.019833765923976898,\n",
       " -0.8182635307312012,\n",
       " -0.5520739555358887,\n",
       " 0.5031420588493347,\n",
       " 0.11975957453250885,\n",
       " -0.2559368312358856,\n",
       " 0.2397879958152771,\n",
       " 0.06577672064304352,\n",
       " -0.4289025068283081,\n",
       " -0.24317021667957306,\n",
       " -0.14757925271987915,\n",
       " 0.21157336235046387,\n",
       " 0.27461254596710205,\n",
       " 0.22511503100395203,\n",
       " -0.4708331525325775,\n",
       " -0.8574920296669006,\n",
       " -0.02177487686276436,\n",
       " -0.44853755831718445,\n",
       " -0.03448502719402313,\n",
       " -0.11906781792640686,\n",
       " -0.015861667692661285,\n",
       " 0.34434258937835693,\n",
       " -0.016430480405688286,\n",
       " 0.012980563566088676,\n",
       " 0.6993362307548523,\n",
       " 0.033979810774326324,\n",
       " 0.05523053556680679,\n",
       " -0.1583712249994278,\n",
       " -0.16747117042541504,\n",
       " -0.10531020164489746,\n",
       " 0.15381643176078796,\n",
       " 0.1834600418806076,\n",
       " 0.3758128881454468,\n",
       " 0.10488469153642654,\n",
       " 0.10315363109111786,\n",
       " -0.18420681357383728,\n",
       " 0.17847377061843872,\n",
       " 0.00675179623067379,\n",
       " -0.3362417221069336,\n",
       " -0.04654860123991966,\n",
       " -0.07281830161809921,\n",
       " 0.3359984755516052,\n",
       " -0.14609700441360474,\n",
       " -0.1303560733795166,\n",
       " 0.2011530101299286,\n",
       " 0.5087595582008362,\n",
       " 0.08232130110263824,\n",
       " -0.6169514060020447,\n",
       " -0.031338367611169815,\n",
       " -0.12919001281261444,\n",
       " 0.9336600303649902,\n",
       " 0.3245353400707245,\n",
       " 0.6953388452529907,\n",
       " -0.40132391452789307,\n",
       " 0.3244902491569519,\n",
       " 0.2555193603038788,\n",
       " 0.4337631165981293,\n",
       " 0.14671939611434937,\n",
       " -0.5932286977767944,\n",
       " -0.031816624104976654,\n",
       " 0.8443653583526611,\n",
       " -0.41845017671585083,\n",
       " 0.21687962114810944,\n",
       " -0.28285878896713257,\n",
       " 0.3259662985801697,\n",
       " -0.6553733348846436,\n",
       " -0.2851952314376831,\n",
       " -0.6581099033355713,\n",
       " 0.020524460822343826,\n",
       " -0.6199097633361816,\n",
       " 0.4603720009326935,\n",
       " -0.01204938068985939,\n",
       " -0.3070217967033386,\n",
       " 0.3087943494319916,\n",
       " -0.25164806842803955,\n",
       " 0.05643918365240097,\n",
       " -0.11782097816467285,\n",
       " 0.3168463110923767,\n",
       " -0.05127453804016113,\n",
       " -0.3068384528160095,\n",
       " -0.17095401883125305,\n",
       " 0.014739036560058594,\n",
       " 0.1785757690668106,\n",
       " -0.06355538964271545,\n",
       " 0.018825169652700424,\n",
       " -0.12788446247577667,\n",
       " -0.32778820395469666,\n",
       " -0.6175008416175842,\n",
       " 0.1459706723690033,\n",
       " -0.37237775325775146,\n",
       " -0.051102034747600555,\n",
       " 0.4314192235469818,\n",
       " -0.5405613780021667,\n",
       " 0.7567560076713562,\n",
       " -0.7137293219566345,\n",
       " -0.2544841766357422,\n",
       " 0.5645225644111633,\n",
       " 0.27692747116088867,\n",
       " 0.19766350090503693,\n",
       " 0.5191313028335571,\n",
       " -0.3918135464191437,\n",
       " -0.28598451614379883,\n",
       " 0.10169398039579391,\n",
       " -0.33268505334854126,\n",
       " 0.4129517078399658,\n",
       " 0.2988393008708954,\n",
       " -0.06726794689893723,\n",
       " -0.27488675713539124,\n",
       " -0.21901759505271912,\n",
       " -0.1902962327003479,\n",
       " -0.02429267019033432,\n",
       " 0.535627007484436,\n",
       " 0.18521657586097717,\n",
       " -0.3048146069049835,\n",
       " 0.42881742119789124,\n",
       " 0.5653741955757141,\n",
       " 0.37660184502601624,\n",
       " -0.04209199175238609,\n",
       " 0.04942576587200165,\n",
       " -0.21875238418579102,\n",
       " 0.020654914900660515,\n",
       " -0.21312639117240906,\n",
       " -0.461240291595459,\n",
       " 0.13770648837089539,\n",
       " 0.15477536618709564,\n",
       " -0.01672995090484619,\n",
       " 0.31614312529563904,\n",
       " 0.12922026216983795,\n",
       " 0.8379207849502563,\n",
       " -0.2982136011123657,\n",
       " 0.36253592371940613,\n",
       " -0.6317927837371826,\n",
       " -0.16911309957504272,\n",
       " -0.030612090602517128,\n",
       " -0.016705501824617386,\n",
       " 0.3017999827861786,\n",
       " 0.1013544350862503,\n",
       " -0.10934463888406754,\n",
       " 0.4302777349948883,\n",
       " 0.24335724115371704,\n",
       " -0.3411864638328552,\n",
       " -0.16308081150054932,\n",
       " 0.10373084247112274,\n",
       " -0.5121428966522217,\n",
       " 0.11344283819198608,\n",
       " -0.3122367858886719,\n",
       " -0.0007045809179544449,\n",
       " -0.32059404253959656,\n",
       " 0.41411465406417847,\n",
       " 0.7915787696838379,\n",
       " -0.44358566403388977,\n",
       " 0.02838616445660591,\n",
       " -0.14671015739440918,\n",
       " 0.9355728626251221,\n",
       " 0.31732887029647827,\n",
       " 0.15252277255058289,\n",
       " -0.3593776524066925,\n",
       " -0.04521377384662628,\n",
       " -0.5125552415847778,\n",
       " -0.019672170281410217,\n",
       " -0.43073707818984985,\n",
       " -0.10627586394548416,\n",
       " -0.2436862289905548,\n",
       " -0.15621735155582428,\n",
       " 0.06002834439277649,\n",
       " -0.13881072402000427,\n",
       " -0.017404455691576004,\n",
       " 0.057945091277360916,\n",
       " -0.009636569768190384,\n",
       " -0.3167246878147125,\n",
       " -0.042741984128952026,\n",
       " 0.2217673510313034,\n",
       " 0.15646682679653168,\n",
       " 0.5740126967430115,\n",
       " 0.5204401016235352,\n",
       " -0.35693469643592834,\n",
       " -0.025433510541915894,\n",
       " -0.137936070561409,\n",
       " -0.10528826713562012,\n",
       " 0.21627052128314972,\n",
       " 0.492230087518692,\n",
       " -0.46693795919418335,\n",
       " 0.17119921743869781,\n",
       " -0.5607571005821228,\n",
       " 0.05041186511516571,\n",
       " -0.31574684381484985,\n",
       " -0.050662241876125336,\n",
       " -0.17060336470603943,\n",
       " -0.33500969409942627,\n",
       " -0.0082288458943367,\n",
       " -0.14728416502475739,\n",
       " -0.13193665444850922,\n",
       " 0.315044105052948,\n",
       " 0.4499262869358063,\n",
       " -0.28949981927871704,\n",
       " -0.10080697387456894,\n",
       " -0.2214975357055664,\n",
       " -0.06701898574829102,\n",
       " -0.03177836537361145,\n",
       " 0.4500855803489685,\n",
       " -0.07014022022485733,\n",
       " 0.27414146065711975,\n",
       " 0.22391724586486816,\n",
       " 0.45037955045700073,\n",
       " -0.3789403736591339,\n",
       " 0.22817052900791168,\n",
       " 0.6533421874046326,\n",
       " -0.16785076260566711,\n",
       " 0.46845123171806335,\n",
       " 0.06732437759637833,\n",
       " -0.03948546573519707,\n",
       " 0.05121646821498871,\n",
       " -0.42156609892845154,\n",
       " -0.060136035084724426,\n",
       " 0.3565683662891388,\n",
       " -0.3417189419269562,\n",
       " 0.2962243854999542,\n",
       " 0.05680873245000839,\n",
       " -0.24514076113700867,\n",
       " -0.5389047265052795,\n",
       " -0.37645208835601807,\n",
       " 0.12636007368564606,\n",
       " -0.1482464075088501,\n",
       " -0.8981519341468811,\n",
       " -0.778575599193573,\n",
       " -0.06285302340984344,\n",
       " -0.12282302975654602,\n",
       " 0.50783771276474,\n",
       " 0.7229653596878052,\n",
       " -0.11796693503856659,\n",
       " -0.027015291154384613,\n",
       " 0.049423184245824814,\n",
       " 0.18237914144992828,\n",
       " 0.31463003158569336,\n",
       " -0.12089153379201889,\n",
       " -0.3058398365974426,\n",
       " 0.4338926076889038,\n",
       " 0.15866605937480927,\n",
       " 0.4603741765022278,\n",
       " -0.2475094348192215,\n",
       " 0.30218949913978577,\n",
       " -0.24633364379405975,\n",
       " 0.2778856158256531,\n",
       " -0.21599739789962769,\n",
       " 0.19833442568778992,\n",
       " -0.08250775933265686,\n",
       " 0.8005658984184265,\n",
       " 0.4460371434688568,\n",
       " 0.21346138417720795,\n",
       " -0.5086102485656738,\n",
       " 0.1890329122543335,\n",
       " -0.3173965811729431,\n",
       " 0.1732758730649948,\n",
       " -0.14784032106399536,\n",
       " -0.12174816429615021,\n",
       " -0.20026907324790955,\n",
       " 0.2173880934715271,\n",
       " 0.08497133105993271,\n",
       " -0.8085939288139343,\n",
       " 0.18668070435523987,\n",
       " -0.4150872230529785,\n",
       " -0.4494190812110901,\n",
       " 0.054704319685697556,\n",
       " 0.21531254053115845,\n",
       " 0.8969378471374512,\n",
       " -0.37764620780944824,\n",
       " -0.19602997601032257,\n",
       " -0.29290705919265747,\n",
       " 0.14833669364452362,\n",
       " 0.13973885774612427,\n",
       " 0.24136145412921906,\n",
       " -0.27437663078308105,\n",
       " -0.49229955673217773,\n",
       " 0.3104358911514282,\n",
       " -0.10798068344593048,\n",
       " -0.3116462528705597,\n",
       " 0.00657343864440918,\n",
       " -0.31675559282302856,\n",
       " -0.4945942759513855,\n",
       " 0.4628642797470093,\n",
       " 0.21617093682289124,\n",
       " -0.5781657695770264,\n",
       " 0.12527772784233093,\n",
       " 0.30019867420196533,\n",
       " 0.2541121244430542,\n",
       " -0.18510237336158752,\n",
       " -0.0901339203119278,\n",
       " -0.1740286946296692,\n",
       " 0.20978333055973053,\n",
       " -0.3132132589817047,\n",
       " -0.15898312628269196,\n",
       " -0.4818764626979828,\n",
       " -0.24415117502212524,\n",
       " -0.14877596497535706,\n",
       " -0.3879469037055969,\n",
       " 0.27399513125419617,\n",
       " -0.1816645860671997,\n",
       " 0.0653880164027214,\n",
       " -0.43347659707069397,\n",
       " -0.35132890939712524,\n",
       " -0.13541676104068756,\n",
       " 0.07691347599029541,\n",
       " 0.23082195222377777,\n",
       " -0.28606247901916504,\n",
       " 0.06667064130306244,\n",
       " -0.40487951040267944,\n",
       " -0.30975717306137085,\n",
       " 0.16390766203403473,\n",
       " 0.4383908808231354,\n",
       " -0.0021386072039604187,\n",
       " -0.21850861608982086,\n",
       " 0.05608168616890907,\n",
       " -0.2612599730491638,\n",
       " -0.40620723366737366,\n",
       " 0.25209352374076843,\n",
       " 0.12140151113271713,\n",
       " -0.3087673485279083,\n",
       " 0.18099573254585266,\n",
       " 0.1996784657239914,\n",
       " 0.2154669612646103,\n",
       " -0.004099782556295395,\n",
       " 0.19284772872924805,\n",
       " 0.6724308729171753,\n",
       " 0.04831727221608162,\n",
       " -0.32483741641044617,\n",
       " -0.15684430301189423,\n",
       " -0.47989973425865173,\n",
       " 0.061505578458309174,\n",
       " 0.027939962223172188,\n",
       " -0.18956942856311798,\n",
       " -0.2189435362815857,\n",
       " -0.056223705410957336,\n",
       " 0.43096768856048584,\n",
       " -0.2798803448677063,\n",
       " 0.021495765075087547,\n",
       " 0.06830395758152008,\n",
       " -0.17437335848808289,\n",
       " 0.06686986982822418,\n",
       " -0.2438163161277771,\n",
       " 0.01850566267967224,\n",
       " 0.3305913507938385,\n",
       " 0.18718552589416504,\n",
       " 0.12956084311008453,\n",
       " 0.20005987584590912,\n",
       " 0.17173364758491516,\n",
       " 0.053571105003356934,\n",
       " 0.06514550745487213,\n",
       " 0.15954986214637756,\n",
       " 1.1354209184646606,\n",
       " -0.27487581968307495,\n",
       " -0.019451968371868134,\n",
       " 0.3545103967189789,\n",
       " 0.19265881180763245,\n",
       " -0.031616926193237305,\n",
       " 0.15529099106788635,\n",
       " -0.16944973170757294,\n",
       " -0.32049474120140076,\n",
       " 0.4320542812347412,\n",
       " 0.4267107844352722,\n",
       " -0.4171471893787384,\n",
       " 0.09925989806652069,\n",
       " -0.055589355528354645,\n",
       " 0.27543869614601135,\n",
       " 0.2631542384624481,\n",
       " -0.07620382308959961,\n",
       " -0.34028205275535583,\n",
       " -0.15283803641796112,\n",
       " -0.31505441665649414,\n",
       " -0.06492343544960022,\n",
       " 0.24469254910945892,\n",
       " 0.3516184687614441,\n",
       " 0.03437570482492447,\n",
       " -0.14393165707588196,\n",
       " -0.12770822644233704,\n",
       " 0.26121580600738525,\n",
       " -0.07144161313772202,\n",
       " 0.5547501444816589,\n",
       " -0.041674334555864334,\n",
       " 0.2776447832584381,\n",
       " -0.17153231799602509,\n",
       " 0.1515517234802246]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mServerlessSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maws\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-east-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeography-chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m Pinecone\u001b[38;5;241m.\u001b[39mfrom_texts([t\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text_chunks], embeddings, index_name\u001b[38;5;241m=\u001b[39mindex_name)\n",
      "File \u001b[1;32md:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\pinecone\\deprecation_warnings.py:39\u001b[0m, in \u001b[0;36minit\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
    "index_name = \"geography-chatbot\"\n",
    "\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
