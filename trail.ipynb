{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello|\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.3.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: pinecone-client in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: ctransformers in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (0.2.27)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (3.10.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.8 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from ctransformers) (0.25.1)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from ctransformers) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub->ctransformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub->ctransformers) (2024.9.0)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain pinecone-client ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (1.24.10)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.10 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pymupdf) (1.24.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.25.1)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.3.8)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (3.1.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (0.20.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-huggingface) (4.45.1)\n",
      "Requirement already satisfied: filelock in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.130)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: sympy in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.document_loaders import PyMuPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"fa012826-08d2-41a5-a61b-9c1ee273defe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from PDF files\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyMuPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 0 of document data\\Gale Encyclopedia of Medicine. Vol. 1. 2nd Edition ( PDFDrive ).pdf\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunks:  5779\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embeddings model\n",
    "def download_huggingface_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_huggingface_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "), model_name='sentence-transformers/paraphrase-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my query result:  384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello, how are you?\")\n",
    "print(\"length of my query result: \", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5421559810638428,\n",
       " 0.18908195197582245,\n",
       " 0.8348346948623657,\n",
       " 0.019833765923976898,\n",
       " -0.8182635307312012,\n",
       " -0.5520739555358887,\n",
       " 0.5031420588493347,\n",
       " 0.11975957453250885,\n",
       " -0.2559368312358856,\n",
       " 0.2397879958152771,\n",
       " 0.06577672064304352,\n",
       " -0.4289025068283081,\n",
       " -0.24317021667957306,\n",
       " -0.14757925271987915,\n",
       " 0.21157336235046387,\n",
       " 0.27461254596710205,\n",
       " 0.22511503100395203,\n",
       " -0.4708331525325775,\n",
       " -0.8574920296669006,\n",
       " -0.02177487686276436,\n",
       " -0.44853755831718445,\n",
       " -0.03448502719402313,\n",
       " -0.11906781792640686,\n",
       " -0.015861667692661285,\n",
       " 0.34434258937835693,\n",
       " -0.016430480405688286,\n",
       " 0.012980563566088676,\n",
       " 0.6993362307548523,\n",
       " 0.033979810774326324,\n",
       " 0.05523053556680679,\n",
       " -0.1583712249994278,\n",
       " -0.16747117042541504,\n",
       " -0.10531020164489746,\n",
       " 0.15381643176078796,\n",
       " 0.1834600418806076,\n",
       " 0.3758128881454468,\n",
       " 0.10488469153642654,\n",
       " 0.10315363109111786,\n",
       " -0.18420681357383728,\n",
       " 0.17847377061843872,\n",
       " 0.00675179623067379,\n",
       " -0.3362417221069336,\n",
       " -0.04654860123991966,\n",
       " -0.07281830161809921,\n",
       " 0.3359984755516052,\n",
       " -0.14609700441360474,\n",
       " -0.1303560733795166,\n",
       " 0.2011530101299286,\n",
       " 0.5087595582008362,\n",
       " 0.08232130110263824,\n",
       " -0.6169514060020447,\n",
       " -0.031338367611169815,\n",
       " -0.12919001281261444,\n",
       " 0.9336600303649902,\n",
       " 0.3245353400707245,\n",
       " 0.6953388452529907,\n",
       " -0.40132391452789307,\n",
       " 0.3244902491569519,\n",
       " 0.2555193603038788,\n",
       " 0.4337631165981293,\n",
       " 0.14671939611434937,\n",
       " -0.5932286977767944,\n",
       " -0.031816624104976654,\n",
       " 0.8443653583526611,\n",
       " -0.41845017671585083,\n",
       " 0.21687962114810944,\n",
       " -0.28285878896713257,\n",
       " 0.3259662985801697,\n",
       " -0.6553733348846436,\n",
       " -0.2851952314376831,\n",
       " -0.6581099033355713,\n",
       " 0.020524460822343826,\n",
       " -0.6199097633361816,\n",
       " 0.4603720009326935,\n",
       " -0.01204938068985939,\n",
       " -0.3070217967033386,\n",
       " 0.3087943494319916,\n",
       " -0.25164806842803955,\n",
       " 0.05643918365240097,\n",
       " -0.11782097816467285,\n",
       " 0.3168463110923767,\n",
       " -0.05127453804016113,\n",
       " -0.3068384528160095,\n",
       " -0.17095401883125305,\n",
       " 0.014739036560058594,\n",
       " 0.1785757690668106,\n",
       " -0.06355538964271545,\n",
       " 0.018825169652700424,\n",
       " -0.12788446247577667,\n",
       " -0.32778820395469666,\n",
       " -0.6175008416175842,\n",
       " 0.1459706723690033,\n",
       " -0.37237775325775146,\n",
       " -0.051102034747600555,\n",
       " 0.4314192235469818,\n",
       " -0.5405613780021667,\n",
       " 0.7567560076713562,\n",
       " -0.7137293219566345,\n",
       " -0.2544841766357422,\n",
       " 0.5645225644111633,\n",
       " 0.27692747116088867,\n",
       " 0.19766350090503693,\n",
       " 0.5191313028335571,\n",
       " -0.3918135464191437,\n",
       " -0.28598451614379883,\n",
       " 0.10169398039579391,\n",
       " -0.33268505334854126,\n",
       " 0.4129517078399658,\n",
       " 0.2988393008708954,\n",
       " -0.06726794689893723,\n",
       " -0.27488675713539124,\n",
       " -0.21901759505271912,\n",
       " -0.1902962327003479,\n",
       " -0.02429267019033432,\n",
       " 0.535627007484436,\n",
       " 0.18521657586097717,\n",
       " -0.3048146069049835,\n",
       " 0.42881742119789124,\n",
       " 0.5653741955757141,\n",
       " 0.37660184502601624,\n",
       " -0.04209199175238609,\n",
       " 0.04942576587200165,\n",
       " -0.21875238418579102,\n",
       " 0.020654914900660515,\n",
       " -0.21312639117240906,\n",
       " -0.461240291595459,\n",
       " 0.13770648837089539,\n",
       " 0.15477536618709564,\n",
       " -0.01672995090484619,\n",
       " 0.31614312529563904,\n",
       " 0.12922026216983795,\n",
       " 0.8379207849502563,\n",
       " -0.2982136011123657,\n",
       " 0.36253592371940613,\n",
       " -0.6317927837371826,\n",
       " -0.16911309957504272,\n",
       " -0.030612090602517128,\n",
       " -0.016705501824617386,\n",
       " 0.3017999827861786,\n",
       " 0.1013544350862503,\n",
       " -0.10934463888406754,\n",
       " 0.4302777349948883,\n",
       " 0.24335724115371704,\n",
       " -0.3411864638328552,\n",
       " -0.16308081150054932,\n",
       " 0.10373084247112274,\n",
       " -0.5121428966522217,\n",
       " 0.11344283819198608,\n",
       " -0.3122367858886719,\n",
       " -0.0007045809179544449,\n",
       " -0.32059404253959656,\n",
       " 0.41411465406417847,\n",
       " 0.7915787696838379,\n",
       " -0.44358566403388977,\n",
       " 0.02838616445660591,\n",
       " -0.14671015739440918,\n",
       " 0.9355728626251221,\n",
       " 0.31732887029647827,\n",
       " 0.15252277255058289,\n",
       " -0.3593776524066925,\n",
       " -0.04521377384662628,\n",
       " -0.5125552415847778,\n",
       " -0.019672170281410217,\n",
       " -0.43073707818984985,\n",
       " -0.10627586394548416,\n",
       " -0.2436862289905548,\n",
       " -0.15621735155582428,\n",
       " 0.06002834439277649,\n",
       " -0.13881072402000427,\n",
       " -0.017404455691576004,\n",
       " 0.057945091277360916,\n",
       " -0.009636569768190384,\n",
       " -0.3167246878147125,\n",
       " -0.042741984128952026,\n",
       " 0.2217673510313034,\n",
       " 0.15646682679653168,\n",
       " 0.5740126967430115,\n",
       " 0.5204401016235352,\n",
       " -0.35693469643592834,\n",
       " -0.025433510541915894,\n",
       " -0.137936070561409,\n",
       " -0.10528826713562012,\n",
       " 0.21627052128314972,\n",
       " 0.492230087518692,\n",
       " -0.46693795919418335,\n",
       " 0.17119921743869781,\n",
       " -0.5607571005821228,\n",
       " 0.05041186511516571,\n",
       " -0.31574684381484985,\n",
       " -0.050662241876125336,\n",
       " -0.17060336470603943,\n",
       " -0.33500969409942627,\n",
       " -0.0082288458943367,\n",
       " -0.14728416502475739,\n",
       " -0.13193665444850922,\n",
       " 0.315044105052948,\n",
       " 0.4499262869358063,\n",
       " -0.28949981927871704,\n",
       " -0.10080697387456894,\n",
       " -0.2214975357055664,\n",
       " -0.06701898574829102,\n",
       " -0.03177836537361145,\n",
       " 0.4500855803489685,\n",
       " -0.07014022022485733,\n",
       " 0.27414146065711975,\n",
       " 0.22391724586486816,\n",
       " 0.45037955045700073,\n",
       " -0.3789403736591339,\n",
       " 0.22817052900791168,\n",
       " 0.6533421874046326,\n",
       " -0.16785076260566711,\n",
       " 0.46845123171806335,\n",
       " 0.06732437759637833,\n",
       " -0.03948546573519707,\n",
       " 0.05121646821498871,\n",
       " -0.42156609892845154,\n",
       " -0.060136035084724426,\n",
       " 0.3565683662891388,\n",
       " -0.3417189419269562,\n",
       " 0.2962243854999542,\n",
       " 0.05680873245000839,\n",
       " -0.24514076113700867,\n",
       " -0.5389047265052795,\n",
       " -0.37645208835601807,\n",
       " 0.12636007368564606,\n",
       " -0.1482464075088501,\n",
       " -0.8981519341468811,\n",
       " -0.778575599193573,\n",
       " -0.06285302340984344,\n",
       " -0.12282302975654602,\n",
       " 0.50783771276474,\n",
       " 0.7229653596878052,\n",
       " -0.11796693503856659,\n",
       " -0.027015291154384613,\n",
       " 0.049423184245824814,\n",
       " 0.18237914144992828,\n",
       " 0.31463003158569336,\n",
       " -0.12089153379201889,\n",
       " -0.3058398365974426,\n",
       " 0.4338926076889038,\n",
       " 0.15866605937480927,\n",
       " 0.4603741765022278,\n",
       " -0.2475094348192215,\n",
       " 0.30218949913978577,\n",
       " -0.24633364379405975,\n",
       " 0.2778856158256531,\n",
       " -0.21599739789962769,\n",
       " 0.19833442568778992,\n",
       " -0.08250775933265686,\n",
       " 0.8005658984184265,\n",
       " 0.4460371434688568,\n",
       " 0.21346138417720795,\n",
       " -0.5086102485656738,\n",
       " 0.1890329122543335,\n",
       " -0.3173965811729431,\n",
       " 0.1732758730649948,\n",
       " -0.14784032106399536,\n",
       " -0.12174816429615021,\n",
       " -0.20026907324790955,\n",
       " 0.2173880934715271,\n",
       " 0.08497133105993271,\n",
       " -0.8085939288139343,\n",
       " 0.18668070435523987,\n",
       " -0.4150872230529785,\n",
       " -0.4494190812110901,\n",
       " 0.054704319685697556,\n",
       " 0.21531254053115845,\n",
       " 0.8969378471374512,\n",
       " -0.37764620780944824,\n",
       " -0.19602997601032257,\n",
       " -0.29290705919265747,\n",
       " 0.14833669364452362,\n",
       " 0.13973885774612427,\n",
       " 0.24136145412921906,\n",
       " -0.27437663078308105,\n",
       " -0.49229955673217773,\n",
       " 0.3104358911514282,\n",
       " -0.10798068344593048,\n",
       " -0.3116462528705597,\n",
       " 0.00657343864440918,\n",
       " -0.31675559282302856,\n",
       " -0.4945942759513855,\n",
       " 0.4628642797470093,\n",
       " 0.21617093682289124,\n",
       " -0.5781657695770264,\n",
       " 0.12527772784233093,\n",
       " 0.30019867420196533,\n",
       " 0.2541121244430542,\n",
       " -0.18510237336158752,\n",
       " -0.0901339203119278,\n",
       " -0.1740286946296692,\n",
       " 0.20978333055973053,\n",
       " -0.3132132589817047,\n",
       " -0.15898312628269196,\n",
       " -0.4818764626979828,\n",
       " -0.24415117502212524,\n",
       " -0.14877596497535706,\n",
       " -0.3879469037055969,\n",
       " 0.27399513125419617,\n",
       " -0.1816645860671997,\n",
       " 0.0653880164027214,\n",
       " -0.43347659707069397,\n",
       " -0.35132890939712524,\n",
       " -0.13541676104068756,\n",
       " 0.07691347599029541,\n",
       " 0.23082195222377777,\n",
       " -0.28606247901916504,\n",
       " 0.06667064130306244,\n",
       " -0.40487951040267944,\n",
       " -0.30975717306137085,\n",
       " 0.16390766203403473,\n",
       " 0.4383908808231354,\n",
       " -0.0021386072039604187,\n",
       " -0.21850861608982086,\n",
       " 0.05608168616890907,\n",
       " -0.2612599730491638,\n",
       " -0.40620723366737366,\n",
       " 0.25209352374076843,\n",
       " 0.12140151113271713,\n",
       " -0.3087673485279083,\n",
       " 0.18099573254585266,\n",
       " 0.1996784657239914,\n",
       " 0.2154669612646103,\n",
       " -0.004099782556295395,\n",
       " 0.19284772872924805,\n",
       " 0.6724308729171753,\n",
       " 0.04831727221608162,\n",
       " -0.32483741641044617,\n",
       " -0.15684430301189423,\n",
       " -0.47989973425865173,\n",
       " 0.061505578458309174,\n",
       " 0.027939962223172188,\n",
       " -0.18956942856311798,\n",
       " -0.2189435362815857,\n",
       " -0.056223705410957336,\n",
       " 0.43096768856048584,\n",
       " -0.2798803448677063,\n",
       " 0.021495765075087547,\n",
       " 0.06830395758152008,\n",
       " -0.17437335848808289,\n",
       " 0.06686986982822418,\n",
       " -0.2438163161277771,\n",
       " 0.01850566267967224,\n",
       " 0.3305913507938385,\n",
       " 0.18718552589416504,\n",
       " 0.12956084311008453,\n",
       " 0.20005987584590912,\n",
       " 0.17173364758491516,\n",
       " 0.053571105003356934,\n",
       " 0.06514550745487213,\n",
       " 0.15954986214637756,\n",
       " 1.1354209184646606,\n",
       " -0.27487581968307495,\n",
       " -0.019451968371868134,\n",
       " 0.3545103967189789,\n",
       " 0.19265881180763245,\n",
       " -0.031616926193237305,\n",
       " 0.15529099106788635,\n",
       " -0.16944973170757294,\n",
       " -0.32049474120140076,\n",
       " 0.4320542812347412,\n",
       " 0.4267107844352722,\n",
       " -0.4171471893787384,\n",
       " 0.09925989806652069,\n",
       " -0.055589355528354645,\n",
       " 0.27543869614601135,\n",
       " 0.2631542384624481,\n",
       " -0.07620382308959961,\n",
       " -0.34028205275535583,\n",
       " -0.15283803641796112,\n",
       " -0.31505441665649414,\n",
       " -0.06492343544960022,\n",
       " 0.24469254910945892,\n",
       " 0.3516184687614441,\n",
       " 0.03437570482492447,\n",
       " -0.14393165707588196,\n",
       " -0.12770822644233704,\n",
       " 0.26121580600738525,\n",
       " -0.07144161313772202,\n",
       " 0.5547501444816589,\n",
       " -0.041674334555864334,\n",
       " 0.2776447832584381,\n",
       " -0.17153231799602509,\n",
       " 0.1515517234802246]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client[grpc] in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (2024.8.30)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (1.65.0)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (1.66.2)\n",
      "Requirement already satisfied: lz4>=3.1.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (4.3.3)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (0.0.7)\n",
      "Requirement already satisfied: protobuf<5.0,>=4.25 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (4.25.5)\n",
      "Requirement already satisfied: protoc-gen-openapiv2<0.0.2,>=0.0.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (0.0.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from pinecone-client[grpc]) (2.2.3)\n",
      "Requirement already satisfied: colorama in d:\\code\\medical chatbot\\medical-chatbot-using-llama\\medical\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client[grpc]) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"pinecone-client[grpc]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing index names: ['medical']\n",
      "Index is already created.\n"
     ]
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Initialize a client\n",
    "pc = Pinecone(api_key='fa012826-08d2-41a5-a61b-9c1ee273defe')\n",
    "\n",
    "# Define index name\n",
    "index_name = \"medical\"\n",
    "\n",
    "# Extract just the names of the indexes\n",
    "existing_index= []\n",
    "for index in pc.list_indexes():\n",
    "    existing_index.append(index['name'])\n",
    "\n",
    "# Print the list of index names for debugging\n",
    "print(\"Existing index names:\", existing_index)\n",
    "\n",
    "# Check if the index already exists\n",
    "if index_name in existing_index:\n",
    "    print(\"Index is already created.\")\n",
    "else:\n",
    "    # Try to create the serverless index\n",
    "    try:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            ),\n",
    "            deletion_protection=\"disabled\"\n",
    "        )\n",
    "        print(\"Index created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deletion_protection': 'disabled',\n",
       " 'dimension': 384,\n",
       " 'host': 'medical-667fvl4.svc.aped-4627-b74a.pinecone.io',\n",
       " 'metric': 'cosine',\n",
       " 'name': 'medical',\n",
       " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       " 'status': {'ready': True, 'state': 'Ready'}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': '', 'usage': {'read_units': 0}, 'vectors': {}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index= pc.Index(index_name)\n",
    "index.fetch([\"id-1\", \"id-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "index = pc.Index(host='medical-667fvl4.svc.aped-4627-b74a.pinecone.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad argument type for built-in operation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Prepare the texts and embeddings for storage\u001b[39;00m\n\u001b[0;32m      6\u001b[0m texts \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n\u001b[1;32m----> 7\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Medical chatbot\\Medical-Chatbot-using-llama\\medical\\Lib\\site-packages\\pinecone\\grpc\\index_grpc.py:334\u001b[0m, in \u001b[0;36mGRPCIndex.fetch\u001b[1;34m(self, ids, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    332\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[1;32m--> 334\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43mFetchRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_grpc_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub\u001b[38;5;241m.\u001b[39mFetch, request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    336\u001b[0m json_response \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mMessageToDict(response)\n",
      "\u001b[1;31mTypeError\u001b[0m: bad argument type for built-in operation"
     ]
    }
   ],
   "source": [
    "# from langchain.vectorstores import Pinecone as PC\n",
    "# Create a Pinecone index object\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Prepare the texts and embeddings for storage\n",
    "texts = [t.page_content for t in text_chunks]\n",
    "docsearch = index.fetch(texts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert response for batch 1: upserted_count: 1000\n",
      "\n",
      "Upsert response for batch 2: upserted_count: 1000\n",
      "\n",
      "Upsert response for batch 3: upserted_count: 1000\n",
      "\n",
      "Upsert response for batch 4: upserted_count: 1000\n",
      "\n",
      "Upsert response for batch 5: upserted_count: 1000\n",
      "\n",
      "Upsert response for batch 6: upserted_count: 779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone Index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "def batch_upsert(index, vectors, batch_size=1000):\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i + batch_size]\n",
    "        upsert_response = index.upsert(vectors=batch)\n",
    "        print(f\"Upsert response for batch {i//batch_size + 1}: {upsert_response}\")\n",
    "\n",
    "# Prepare the embeddings\n",
    "embeddings_to_upsert = [\n",
    "    (f\"vec{i}\", embeddings.embed_documents([t.page_content])[0], {\"content\": t.page_content}) \n",
    "    for i, t in enumerate(text_chunks)\n",
    "]\n",
    "\n",
    "# Call the batch upsert function\n",
    "batch_upsert(index, embeddings_to_upsert, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
